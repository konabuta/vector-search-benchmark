{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEIR Benchmarking for Azure AI Search (Part2)\n",
    "\n",
    "In this part2 notebook, we will show how to use the BEIR package to benchmark Azure AI Search with various types of searches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Vectorize query text if True\n",
    "vectorize_query = False\n",
    "\n",
    "# BEIR datasets to download\n",
    "dataset_name = \"scifact\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variabls from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure AI Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "service_name = \"benchmark-ai-search\"\n",
    "index_name = dataset_name + \"-vector\"\n",
    "\n",
    "admin_key = os.environ[\"SEARCH_ADMIN_KEY\"]\n",
    "endpoint = \"https://{}.search.windows.net/\".format(service_name)\n",
    "\n",
    "# admin_client = SearchIndexClient(endpoint=endpoint,\n",
    "#                     index_name=index_name,\n",
    "#                     credential=AzureKeyCredential(admin_key))\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=endpoint, index_name=index_name, credential=AzureKeyCredential(admin_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download BEIR datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\n",
    "    \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(\n",
    "        dataset_name\n",
    "    )\n",
    ")\n",
    "out_dir = \"./datasets\"\n",
    "data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_path).load(\n",
    "    split=\"test\"\n",
    ")  # pull data from corpus and queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import VectorizedQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")\n",
    "\n",
    "model = \"text-embedding-ada-002-v2\"\n",
    "\n",
    "\n",
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "# Read the text-sample.json\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text, model=model):\n",
    "    return openai_client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vectorize_query == True:\n",
    "    query_ids = list(queries)\n",
    "    queriesVector = {}\n",
    "    dict_results = {}\n",
    "    for query_id in query_ids:\n",
    "        query = queries[query_id]\n",
    "        queriesVector[query_id] = generate_embeddings(query)\n",
    "    with open(\"scifact_query_vector.json\", \"w\") as f:\n",
    "        json.dump(queriesVector, f)\n",
    "else:\n",
    "    queriesVector = json.load(open(\"scifact_query_vector.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for BEIR dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = list(queries)\n",
    "dict_results = {}\n",
    "for query_id in query_ids:\n",
    "    query = queries[query_id]\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        include_total_count=True,\n",
    "        select=\"corpusId, title, text\",\n",
    "        top=100,\n",
    "        query_type=\"simple\",\n",
    "    )\n",
    "    id_score = {}\n",
    "    for result in results:\n",
    "        id_score[result[\"corpusId\"]] = result[\"@search.score\"]\n",
    "    dict_results[query_id] = id_score\n",
    "\n",
    "# Evaluate the performance\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(\n",
    "    qrels, dict_results, [1, 3, 5, 10, 50, 100]\n",
    ")\n",
    "print(ndcg, _map, recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = list(queries)\n",
    "dict_results = {}\n",
    "for query_id in query_ids:\n",
    "    query = queries[query_id]\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        include_total_count=True,\n",
    "        select=\"corpusId, title, text\",\n",
    "        top=50,\n",
    "        semantic_configuration_name=\"my-semantic-config\",\n",
    "        query_type=\"semantic\",\n",
    "    )\n",
    "    id_score = {}\n",
    "    for result in results:\n",
    "        id_score[result[\"corpusId\"]] = result[\"@search.reranker_score\"]\n",
    "    dict_results[query_id] = id_score\n",
    "\n",
    "# Evaluate the performance\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(\n",
    "    qrels, dict_results, [1, 3, 5, 10, 50, 100]\n",
    ")\n",
    "print(ndcg, _map, recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HNSW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = list(queries)\n",
    "dict_results = {}\n",
    "for query_id in query_ids:\n",
    "    query = queries[query_id]\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=queriesVector[query_id],\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"titleVector, textVector\",\n",
    "    )\n",
    "    results = search_client.search(\n",
    "        vector_queries=[vector_query],\n",
    "        include_total_count=True,\n",
    "        select=\"corpusId, title, text\",\n",
    "        top=50,\n",
    "    )\n",
    "    id_score = {}\n",
    "    for result in results:\n",
    "        id_score[result[\"corpusId\"]] = result[\"@search.score\"]\n",
    "    dict_results[query_id] = id_score\n",
    "\n",
    "# Evaluate the performance\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(\n",
    "    qrels, dict_results, [1, 3, 5, 10, 50, 100]\n",
    ")\n",
    "print(ndcg, _map, recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exhausive KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = list(queries)\n",
    "dict_results = {}\n",
    "for query_id in query_ids:\n",
    "    query = queries[query_id]\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=queriesVector[query_id],\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"titleVector, textVector\",\n",
    "        exhaustive=True,\n",
    "    )\n",
    "    results = search_client.search(\n",
    "        vector_queries=[vector_query],\n",
    "        include_total_count=True,\n",
    "        select=\"corpusId, title, text\",\n",
    "        top=50,\n",
    "    )\n",
    "    id_score = {}\n",
    "    for result in results:\n",
    "        id_score[result[\"corpusId\"]] = result[\"@search.score\"]\n",
    "    dict_results[query_id] = id_score\n",
    "\n",
    "# Evaluate the performance\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(\n",
    "    qrels, dict_results, [1, 3, 5, 10, 50, 100]\n",
    ")\n",
    "print(ndcg, _map, recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HNSW + Reranker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = list(queries)\n",
    "dict_results = {}\n",
    "for query_id in query_ids:\n",
    "    query = queries[query_id]\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=queriesVector[query_id],\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"titleVector, textVector\",\n",
    "    )\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        vector_queries=[vector_query],\n",
    "        include_total_count=True,\n",
    "        select=\"corpusId, title, text\",\n",
    "        top=50,\n",
    "        semantic_configuration_name=\"my-semantic-config\",\n",
    "        query_type=\"semantic\",\n",
    "    )\n",
    "    id_score = {}\n",
    "    for result in results:\n",
    "        id_score[result[\"corpusId\"]] = result[\"@search.reranker_score\"]\n",
    "    dict_results[query_id] = id_score\n",
    "\n",
    "# Evaluate the performance\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(\n",
    "    qrels, dict_results, [1, 3, 5, 10, 50, 100]\n",
    ")\n",
    "print(ndcg, _map, recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExhaustiveKNN + Reranker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = list(queries)\n",
    "dict_results = {}\n",
    "for query_id in query_ids:\n",
    "    query = queries[query_id]\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=queriesVector[query_id],\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"titleVector, textVector\",\n",
    "        exhaustive=True,\n",
    "    )\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        vector_queries=[vector_query],\n",
    "        include_total_count=True,\n",
    "        select=\"corpusId, title, text\",\n",
    "        top=50,\n",
    "        semantic_configuration_name=\"my-semantic-config\",\n",
    "        query_type=\"semantic\",\n",
    "    )\n",
    "    id_score = {}\n",
    "    for result in results:\n",
    "        id_score[result[\"corpusId\"]] = result[\"@search.reranker_score\"]\n",
    "    dict_results[query_id] = id_score\n",
    "\n",
    "# Evaluate the performance\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(\n",
    "    qrels, dict_results, [1, 3, 5, 10, 50, 100]\n",
    ")\n",
    "print(ndcg, _map, recall, precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
